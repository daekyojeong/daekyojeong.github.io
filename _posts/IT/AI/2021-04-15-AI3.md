---
title: "모델 평가"
author: Daekyo Jeong
date: 2021-04-15 15:00:00 +0900
categories: [IT, AI]
tags: [IT, AI, Machine Learning, Deep Learning]

math: true
---

---
**Contents**

{:.no_toc}

* Will be replaced with the ToC, excluding the "Contents" header
{:toc}
---

<br/>

# **모델 평가**  

모델에 따라 평가 과정에서 서로 다른 지표를 사용하게 된다.  
이러한 평가 지표 중 대부분은 모델의 일부 성능에 대한 단편적인 부분만 반영하게 된다.  
만약 적절한 평가 지표를 사용하지 않는다면, 모델의 문제점을 발견하지 못할 수 있고 잘못된 결론을 도출할 위험이 있다.  

### **정확도**  

정확도를 이용한 평가는 가장 기본적인 평가 방법이다.  
이 방법은 다음 식과 같다.  

$$
Accuracy = \frac{n_{correct}}{n_{total}}
$$

가장 간단하고 직관적인 평가 지표이지만 명백한 단점이 존재한다.  
클래스별 샘플의 개수가 불균형한 경우, 정확도는 불균형한 정도에 많은 영향을 받게 된다.  

예를 들어, 강아지와 고양이를 판별하는 문제에서 강아지 사진은 9,900장, 고양이 사진은 100장이라고 하자.  
정확도로 모델을 평가하게 된다면, 모든 사진을 강아지라고 분류해도 이 모델의 정확도는 99%이다.  

이러한 문제점을 해결하기 위한 방법은 여러가지가 있다.  
그 중하나로 평균 정확도를 평가 지표로 활용하는 방법이 있다.  
평균 정확도는 클래스별 정확도의 평균을 나타낸다.  
위의 예시에서는 강아지 클래스의 정확도는 100%이고, 고양이 클래스의 정확도는 0%이다.  
따라서 평균 정확도는 50%가 될 것이다.  

### **Precision, Recall**  

Precision(정밀도)란 예측 결과가 양성인 것 중에서 실제 양성인 것의 비율이다.  

Recall(재현율)은 실제 양성인 것 중에 양성이라고 예측해낸 것의 비율이다.  

이러한 정밀도와 재현율을 이용한 평가에는 P-R 곡선을 그려보는 방법이 있다.  

P-R 곡선의 x축은 재현율, y축은 정밀도이다.  

이 외에도 F1 score, ROC 곡선 등을 이용하여 모델을 평가할 수 있다.  

F1 Score는 정밀도와 재현율의 조화 평균으로 수식은 다음과 같다.  

$$
F1 = \frac{2 \times precision \times recall}{precision + recall}
$$

### **ROC 곡선**  


### **RMSE(평균제곱근오차)**  

회귀 모델을 평가할 때 RMSE는 자주 사용된다.  
하지만 특정 경우 RMSE는 좋은 평가지표가 되지 못한다.  
일반적인 상황에서 RMSE는 예측값이 실제값에서 벗어난 정도를 잘 반영한다.  
하지만 벗어난 정도가 매우 큰 특이점(outlier)가 존재하는 경우, 이러한 특이점들 때문에 RMSE 지표는 매우 높아진다.  

이러한 경우는 어떻게 해결해야 할까?  

첫 번째는 이러한 특이점들이 노이즈인 경우이다.  
이 경우 전처리 과정에서 이러한 데이터들을 제거해야 한다.  

두 번째는 노이즈가 아닌 경우이다.  
이 경우 모델의 성능을 향상시켜 특이점 데이터에 대해서도 원활한 예측이 가능하도록 해야한다.  

마지막으로 다른 평가 지표를 사용하는 방법이다.  
MAPE(평균절대비오차)와 같은 평가 지표는 RMSE보다 더 견고하다고 알려져 있다.  
이러한 지표를 이용할 수도 있을 것이다.  


<br/>
