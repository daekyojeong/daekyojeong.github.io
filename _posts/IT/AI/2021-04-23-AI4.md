---
title: "모델 평가 2"
author: Daekyo Jeong
date: 2021-04-23 15:00:00 +0900
categories: [IT, AI]
tags: [IT, AI, Machine Learning, Deep Learning]

math: true
---

---
**Contents**

{:.no_toc}

* Will be replaced with the ToC, excluding the "Contents" header
{:toc}
---

<br/>

# **모델 평가**  

### **코사인 거리의 응용**  

모델 훈련 과정에서 샘플 사이의 거리를 비교하게 되는 경우들이 많다.  

이 때 샘플 사이의 거리를 어떻게 측정할 것인지 정하는 것은 최적화와 모델 훈련의 기초가 된다.  

머신러닝 문제에서 특징은 벡터의 형태로 표현되는 경우가 많다.  
특징 벡터 사이의 유사도를 분석할 때 코사인 유사도를 자주 사용하게 된다.  
코사인 유사도 값의 범위는 [-1, 1]이며, 같은 벡터 사이의 유사도는 1이 된다.  
만약 거리와 유사한 형태로 표현하고 싶다면 (1 - 코사인 유사도)를 한 것이 코사인 거리가 된다.  
따라서 코사인 거리의 값의 범위는 [0, 2]가 되고 동일한 두 벡터의 코사인 거리는 0이 된다.  

두 벡터 A, B에 대한 코사인 유사도는 다음과 같이 정의된다.  

$$
cos(A, B) = \frac{A \times B}{\parallel A\parallel_{2}\parallel B\parallel_{2}}
$$

즉, 두 벡터 사이의 코사인 유사도는 절대 크기가 아니라, 각도에 초점이 맞춰져 있다.  
한 쌍의 유사한 텍스트에서 길이는 많이 다르지만 내용이 비슷한 경우, 특징 공간에서의 유클리드 거리는 일반적으로 커지게 된다.  
하지만 코사인 유사도를 사용한다면, 그들 사이의 각도가 작기 때문에 유사도가 높게 측정된다.  

이 외에도 텍스트, 이미지, 비디오 등의 데이터를 사용하는 영역들은 특징의 차원이 큰 경우가 많은데, 코사인 유사도는 고차원 데이터에 대해서도 안정적인 결과를 얻을 수 있지만, 유클리드 거리의 수치는 차원의 영향을 받아 값의 범위가 불안정하고 의미 역시 비교적 모호해진다.  

정리하자면, 유클리드 거리는 수치상의 절대 차이를 나타내고, 코사인 거리는 방향과 크기의 상대적 차이를 반영한다.  


### **A/B 테스트**  

A/B 테스트는 새로운 기능이나 알고리즘, 모델등의 성능을 검증하거나, 어떤 영향을 끼치는지를 테스트하는 방법이다.  
A/B 테스트를 진행해야 하는 이유는 다음과 같다.  

1. 오프라인 평가만으로는 모델의 과적합 위험을 모두 제거할 수 없다. 따라서 오프라인 평가 결과는 온라인 평가 결과를 완벽히 대체할 수 없다.  
2. 오프라인과 온라인 평가 환경은 동일하지 않다. 일반적으로 오프라인 평가는 온라인 환경에서 발생하는 다양한 상황들을 반영하지 못한다. 따라서 오프라인 평가 결과는 가장 이상적인 환경에서의 결과라고 할 수 있다.  
3. 온라인 상의 비지니스 지표를 오프라인에서 평가하기 힘들다. 일반적으로 오프라인 평가는 모델 자체에 대한 평가를 진행할 뿐이다.  

A/B 테스트를 진행하는 방법은 사용자에 대한 분할-실행(버킷 테스트) 방법을 사용하는 것이다.  
사용자를 실험군과 대조군으로 분류하고, 실험군의 사용자는 새로운 모델, 대조군의 사용자는 기존 모델을 사용한다.  
버킷의 형성 과정에서 샘플의 독립성과 샘플 방식의 무편향성을 주의하고, 동일한 사용자는 하나의 버킷으로만 갈 수 있도록한다.  


### **모델 평가 방법**  

##### 홀드아웃(Holdout)  

홀드아웃 검증은 가장 간단하고 직접적인 검증 방법이다.  
이 방법은 초기 데이터를 임의로 훈련 데이터와 테스트 데이터로 분할한다.  
훈련 데이터를 모델 훈련에 사용하고, 테스트 데이터를 모델 검증에 사용한다.  
여기에 ROC 곡선이나, 정확도 등의 앞에서 배운 지표를 활용하여 모델의 성능을 평가한다.  

이 방법의 단점은 명확하다.  
테스트 데이터의 결과는 초기 데이터를 어떻게 분류하느냐에 따라 크게 영향을 받게 된다.  
이러한 단점 때문에 교차 검증 방법이 나오게 되었다.  

##### 교차 검증  

- k-fold 교차 검증  

우선, 모든 샘플을 k개의 크기가 같은 하위 샘플로 분할한다.  
이 k개의 샘플 세트는 돌아가면서 검증 세트가 된다.  
그리고 나머지 샘플들은 모델 훈련에 사용된다.  
최정적으로 k번의 평가 지표의 평균값을 최종 평가 지표로 사용한다.  

- LOOCV(Leave-One-Out Cross-Validation)  

매번 하나의 샘플을 남겨 검증 세트로 사용하고, 나머지 샘플들은 모델 훈련에 사용한다.  
샘플의 수가 n이라면 n개의 샘플에 대해 검증을 진행한다.  
그리고 모든 평가 지표의 평균값을 최종 평가 지표로 사용한다.  
샘플의 수가 많은 상황에서 LOOCV 방법은 연산량이 매우 많아지게 된다.  
이러한 이유로 별로 선호되지 않는 검증 방법이다.  

##### 부트스트래핑(bootstrapping)  

홀드아웃과 교차 검증 모두 훈련, 테스트 세트를 분할하는 방법에 기반하여 평가를 진행한다.  
하지만 샘플의 규모가 비교적 작을 경우 분할하게 되면 훈련 세트의 규모 또한 줄어들 수 밖에 없다.  
부트스트래핑 방법은 이러한 문제를 해결하기 위해 고안된 방법이다.  

부트스트래핑은 총 n개의 샘플 집합에서 n번의 복원 추출법을 사용하여 n개의 훈련 세트를 획득한다.  
n번의 샘플링 과정에서 어떤 샘플은 중복되어 추출되었을 것이다.  
또한, 어떤 샘플은 한 번도 추출되지 않았을 수도 있다.  
이렇게 추출되지 않은 샘플을 검정 세트로 사용하고 모델에 대한 검증을 진행한다.  
이것이 OOB(Out-of-Bag) 검증 세트이다.  
<br/>
