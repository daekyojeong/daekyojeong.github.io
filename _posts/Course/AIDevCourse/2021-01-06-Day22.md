---
title: "[프로그래머스 인공지능스쿨] Week5-1 Machine Learning 기초 : 결정이론"
author: Daekyo Jeong
date: 2021-01-06 00:00:00 +0900
categories: [Course, AI Dev Course]
tags: [Programmers, AI, Python]

math: true
---

# **강의**   
<br/>

## **결정 이론(Decision Theory)**  


### **$$\rhd$$ 결정이론이란?**  

새로운 값 x가 주어졌을 때 확률모델 p(x,t)에 기반해 최적의 결정을 내리는 것  

- 추론단계: 결합확률분포 $$p(x, C_{k})$$를 구하는 것  
- 결정단계: 추론단계를 통해 어떻게 최적의 결정을 내릴 것인지  

직관적으로 볼 때 $$p(C_{k}|x)$$를 최대화시키는 k를 구하는 것이 좋은 결정  

### **$$\rhd$$ 확률 변수(Random Variable)**  

확률 변수 X는 표본 집합 S의 원소 e를 실수 값 $$ X(e) = x$$ 에 대응시키는 함수이다.  

- 대문자 X, Y ... : 확률 변수
- 소문자 x, y ... : 확률 변수가 가질 수 있는 값  
- 확률 P는 집합 S의 부분집합을 실수값에 대응시키는 함수이다.

### **$$\rhd$$ 확률 변수의 성질**  

- 덧셈법칙  

$$
p(X) = \sum_{Y}p(X,Y)
$$

- 곱셈법칙  

$$
p(X,Y)=p(X|Y)p(Y) = p(Y|X)p(X)
$$

- 베이즈 확률  

$$
p(Y|X) = \frac{p(X|Y)p(Y)}{\sum_{Y}p(X|Y)p(Y)}  
$$

$$
posterior = \frac{likelihood \times prior}{normalization}
$$

posterior : 사후 확률  
likelihood: 가능도(우도)  
prior: 사전확률  
normalization: Y와 상관없는 상수. X의 경계확률(marginal) p(X)

### **$$\rhd$$ 확률 변수의 함수**  

확률 변수 X의 함수 Y = g(X)와 역함수 w(Y) = X 가 주어졌을 때 다음이 성립한다.  

$$
p_{y}(Y) = p_{x}(x)|\frac{dx}{dy}|
$$

### **$$\rhd$$ 정규분포(Gaussian Distribution)**  

단일 변수 x를 위한 가우시안 분포  

$$
N(x|\mu, \sigma^{2}) = \frac{1}{(2\pi\sigma^{2})^{1/2}}exp\{-\frac{1}{2\sigma^{2}}(x-\mu)^{2}\}
$$

$$
\int^{\infty}_{-\infty}N(x|\mu, \sigma^{2})dx = 1
$$


<br/>
